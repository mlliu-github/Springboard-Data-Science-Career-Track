{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import emoji.core\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Working Directory and Concatenate Multiple Datasets into One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory C:\\Users\\melin\n",
      "Directory changed successfully C:\\Users\\melin\\Documents\\Springboard Data Science Career Track\\Capstone Projects\\Capstone Project 2\\COVID-19 Tweets\\CP2data\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\melin\\\\Documents\\\\Springboard Data Science Career Track\\\\Capstone Projects\\\\Capstone Project 2\\\\COVID-19 Tweets\\\\CP2data'\n",
    "\n",
    "# Check current working directory.\n",
    "retval = os.getcwd()\n",
    "print(\"Current working directory %s\" % retval)\n",
    "\n",
    "# Now change the directory\n",
    "os.chdir(path)\n",
    "\n",
    "# Check current working directory.\n",
    "retval = os.getcwd()\n",
    "\n",
    "print(\"Directory changed successfully %s\" % retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use glob to match the pattern ‘csv’\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all files in the list\n",
    "df_tweets = pd.concat([pd.read_csv(f) for f in all_filenames ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>reply_to_status_id</th>\n",
       "      <th>reply_to_user_id</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>country_code</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_type</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>account_lang</th>\n",
       "      <th>account_created_at</th>\n",
       "      <th>verified</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1244051646071611394</td>\n",
       "      <td>860252856829587457</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>IMSS_SanLuis</td>\n",
       "      <td>Ante cualquier enfermedad respiratoria, no te ...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1008</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-05-04T22:00:38Z</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244051645039706112</td>\n",
       "      <td>1125933654943895553</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>intrac_ccs</td>\n",
       "      <td>#ATENCIÓN En el Terminal Nuevo Circo se implem...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-05-08T01:21:16Z</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1244051645975191557</td>\n",
       "      <td>80943559</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>rlieving</td>\n",
       "      <td>“People are just storing up. They are staying ...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136</td>\n",
       "      <td>457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-10-08T21:06:08Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1244051646750928897</td>\n",
       "      <td>817072420947247104</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>Tu_IMSS_Coah</td>\n",
       "      <td>Si empezaste a trabajar, necesitas dar de alta...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1549</td>\n",
       "      <td>170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-05T18:17:00Z</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1244051647032102914</td>\n",
       "      <td>788863557349670913</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>Tabasco_IMSS</td>\n",
       "      <td>Una sociedad informada está mejor preparada an...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>868</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-19T22:05:03Z</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             status_id              user_id            created_at  \\\n",
       "0  1244051646071611394   860252856829587457  2020-03-29T00:00:00Z   \n",
       "1  1244051645039706112  1125933654943895553  2020-03-29T00:00:00Z   \n",
       "2  1244051645975191557             80943559  2020-03-29T00:00:00Z   \n",
       "3  1244051646750928897   817072420947247104  2020-03-29T00:00:00Z   \n",
       "4  1244051647032102914   788863557349670913  2020-03-29T00:00:00Z   \n",
       "\n",
       "    screen_name                                               text     source  \\\n",
       "0  IMSS_SanLuis  Ante cualquier enfermedad respiratoria, no te ...  TweetDeck   \n",
       "1    intrac_ccs  #ATENCIÓN En el Terminal Nuevo Circo se implem...  TweetDeck   \n",
       "2      rlieving  “People are just storing up. They are staying ...  TweetDeck   \n",
       "3  Tu_IMSS_Coah  Si empezaste a trabajar, necesitas dar de alta...  TweetDeck   \n",
       "4  Tabasco_IMSS  Una sociedad informada está mejor preparada an...  TweetDeck   \n",
       "\n",
       "   reply_to_status_id  reply_to_user_id reply_to_screen_name  is_quote  ...  \\\n",
       "0                 NaN               NaN                  NaN     False  ...   \n",
       "1                 NaN               NaN                  NaN     False  ...   \n",
       "2                 NaN               NaN                  NaN     False  ...   \n",
       "3                 NaN               NaN                  NaN     False  ...   \n",
       "4                 NaN               NaN                  NaN     False  ...   \n",
       "\n",
       "   retweet_count  country_code  place_full_name place_type followers_count  \\\n",
       "0              0           NaN              NaN        NaN            1008   \n",
       "1              1           NaN              NaN        NaN              90   \n",
       "2              0           NaN              NaN        NaN             136   \n",
       "3              0           NaN              NaN        NaN            1549   \n",
       "4              0           NaN              NaN        NaN             868   \n",
       "\n",
       "  friends_count  account_lang    account_created_at  verified lang  \n",
       "0            41           NaN  2017-05-04T22:00:38Z     False   es  \n",
       "1           316           NaN  2019-05-08T01:21:16Z     False   es  \n",
       "2           457           NaN  2009-10-08T21:06:08Z     False   en  \n",
       "3           170           NaN  2017-01-05T18:17:00Z     False   es  \n",
       "4           125           NaN  2016-10-19T22:05:03Z     False   es  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check first 5 rows of df_tweets dataset\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14607013 entries, 0 to 355386\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   status_id             int64  \n",
      " 1   user_id               int64  \n",
      " 2   created_at            object \n",
      " 3   screen_name           object \n",
      " 4   text                  object \n",
      " 5   source                object \n",
      " 6   reply_to_status_id    float64\n",
      " 7   reply_to_user_id      float64\n",
      " 8   reply_to_screen_name  object \n",
      " 9   is_quote              bool   \n",
      " 10  is_retweet            bool   \n",
      " 11  favourites_count      int64  \n",
      " 12  retweet_count         int64  \n",
      " 13  country_code          object \n",
      " 14  place_full_name       object \n",
      " 15  place_type            object \n",
      " 16  followers_count       int64  \n",
      " 17  friends_count         int64  \n",
      " 18  account_lang          float64\n",
      " 19  account_created_at    object \n",
      " 20  verified              bool   \n",
      " 21  lang                  object \n",
      "dtypes: bool(3), float64(3), int64(6), object(10)\n",
      "memory usage: 2.2+ GB\n"
     ]
    }
   ],
   "source": [
    "#Get summary of df_tweets dataframe\n",
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status_id                      0\n",
       "user_id                        0\n",
       "created_at                     0\n",
       "screen_name                    2\n",
       "text                           0\n",
       "source                        83\n",
       "reply_to_status_id      12861933\n",
       "reply_to_user_id        12495830\n",
       "reply_to_screen_name    12495830\n",
       "is_quote                       0\n",
       "is_retweet                     0\n",
       "favourites_count               0\n",
       "retweet_count                  0\n",
       "country_code            13950294\n",
       "place_full_name         13947685\n",
       "place_type              13947685\n",
       "followers_count                0\n",
       "friends_count                  0\n",
       "account_lang            14607013\n",
       "account_created_at             0\n",
       "verified                       0\n",
       "lang                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check sum of missing values in each column of df_tweets dataframe\n",
    "df_tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually Remove Redundant Columns and Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows in which text are not English\n",
    "df_tweets = df_tweets[df_tweets.lang == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove columns with missing percentage of 60% or more\n",
    "df_tweets = df_tweets.loc[:, df_tweets.isnull().mean() < .6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8133785 entries, 2 to 355386\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Dtype \n",
      "---  ------              ----- \n",
      " 0   created_at          object\n",
      " 1   screen_name         object\n",
      " 2   text                object\n",
      " 3   source              object\n",
      " 4   is_quote            bool  \n",
      " 5   is_retweet          bool  \n",
      " 6   favourites_count    int64 \n",
      " 7   retweet_count       int64 \n",
      " 8   followers_count     int64 \n",
      " 9   friends_count       int64 \n",
      " 10  account_created_at  object\n",
      " 11  verified            bool  \n",
      " 12  lang                object\n",
      "dtypes: bool(3), int64(4), object(6)\n",
      "memory usage: 705.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#Remove redundant columns \n",
    "df_tweets = df_tweets.drop(['status_id', 'user_id'], axis = 1)\n",
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(813378, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Randomly drop additional 90% of rows  \n",
    "df_tweets = df_tweets.sample(frac=.1)\n",
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest tweet:  2020-03-29 00:00:00\n",
      "Latest tweet:  2020-04-30 23:59:58 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert created_at and account_created_at variables from object to datetime64 \n",
    "df_tweets['created_at'] = df_tweets['created_at'].astype('datetime64')\n",
    "df_tweets['account_created_at'] = df_tweets['account_created_at'].astype('datetime64')\n",
    "# Check for earliest and latest tweet\n",
    "print(\"Earliest tweet: \", df_tweets['created_at'].min())\n",
    "print(\"Latest tweet: \", df_tweets['created_at'].max(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Twitter Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for replacing contractions\n",
    "contractions = { \n",
    "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is / how does\",\n",
    "\"I'd\": \"I had / I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I shall / I will\",\n",
    "\"I'll've\": \"I shall have / I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "def replace_contractions(text):\n",
    "    text = text.replace(\"’\",\"'\")\n",
    "    words = text.split()\n",
    "    reformed = [contractions[word] if word in contractions else word for word in words]\n",
    "    text = \" \".join(reformed)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply replace contractions function to cleaned_text column in df_tweets dataframe\n",
    "df_tweets['cleaned_text'] = df_tweets['text'].apply(lambda x: replace_contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for twitter text cleaning \n",
    "def tweet_cleaner(text):\n",
    "    text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                  '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', text) #remove url links\n",
    "    text = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", text) #remove twitter handles (@user)\n",
    "    # convert emojis to text\n",
    "    text = emoji.core.demojize(text)\n",
    "    text = text.replace(\":\",\" \")\n",
    "    # remove punctuations, numbers, and special characters \n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    # remove whitespaces \n",
    "    text = ' '.join(text.split()) \n",
    "    # convert text to lowercase\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply text cleaning function to cleaned_text column in df_tweets dataframe\n",
    "df_tweets['cleaned_text'] = df_tweets['cleaned_text'].apply(lambda x: tweet_cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for lemmatizing words\n",
    "def lemmatize_text(text):\n",
    "    wl = WordNetLemmatizer()\n",
    "    token_words=word_tokenize(str(text))\n",
    "    token_words\n",
    "    lemmatize_text=[]\n",
    "    for word in token_words:\n",
    "        lemmatize_text.append(wl.lemmatize(word))\n",
    "        lemmatize_text.append(\" \")\n",
    "    return \"\".join(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply lemmatizing text function to cleaned_text column in df_tweets dataframe\n",
    "df_tweets['cleaned_text'] = df_tweets['cleaned_text'].apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for stemming words\n",
    "def stem_text(text):\n",
    "    ps = PorterStemmer()\n",
    "    token_words=word_tokenize(str(text))\n",
    "    token_words\n",
    "    stem_text=[]\n",
    "    for word in token_words:\n",
    "        stem_text.append(ps.stem(word))\n",
    "        stem_text.append(\" \")\n",
    "    return \"\".join(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply stemming text function to cleaned_text column in df_tweets dataframe\n",
    "df_tweets['cleaned_text'] = df_tweets['cleaned_text'].apply(lambda x: stem_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop words in cleaned_text column\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    no_stopword_text = [w for w in str(text).split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the remove stop words function to cleaned_text column in df_tweets dataframe\n",
    "df_tweets['cleaned_text'] = df_tweets['cleaned_text'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>account_created_at</th>\n",
       "      <th>verified</th>\n",
       "      <th>lang</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197806</th>\n",
       "      <td>2020-04-14 14:15:35</td>\n",
       "      <td>chan_chan_braby</td>\n",
       "      <td>You know what makes me laugh..this guy who cle...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2976</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>265</td>\n",
       "      <td>2019-09-30 14:27:58</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>know make laugh thi guy clearli would click fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323869</th>\n",
       "      <td>2020-04-01 14:55:24</td>\n",
       "      <td>marla_justmarla</td>\n",
       "      <td>Thx for that self-aggrandizing rally you held ...</td>\n",
       "      <td>Twitter for iPad</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>17134</td>\n",
       "      <td>0</td>\n",
       "      <td>1488</td>\n",
       "      <td>2071</td>\n",
       "      <td>2011-09-27 19:47:27</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>thx self aggrand ralli held walmart target cv ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378746</th>\n",
       "      <td>2020-03-31 15:39:23</td>\n",
       "      <td>winsoar</td>\n",
       "      <td>Song about the things we have to think twice a...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>26931</td>\n",
       "      <td>4</td>\n",
       "      <td>69280</td>\n",
       "      <td>37638</td>\n",
       "      <td>2008-07-12 18:28:11</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>song thing think twice touch due coronaviru covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55558</th>\n",
       "      <td>2020-04-10 05:09:30</td>\n",
       "      <td>IExpressSports</td>\n",
       "      <td>#Wimbledon was scheduled to be played on the c...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>81622</td>\n",
       "      <td>364</td>\n",
       "      <td>2013-08-13 04:44:51</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>wimbledon wa schedul play club grass court out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352576</th>\n",
       "      <td>2020-04-09 17:42:01</td>\n",
       "      <td>TalentCanadaMag</td>\n",
       "      <td>Employer council urges Quebec to open as many ...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>38</td>\n",
       "      <td>2019-10-21 18:59:02</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>employ council urg quebec open mani busi possi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_at      screen_name  \\\n",
       "197806 2020-04-14 14:15:35  chan_chan_braby   \n",
       "323869 2020-04-01 14:55:24  marla_justmarla   \n",
       "378746 2020-03-31 15:39:23          winsoar   \n",
       "55558  2020-04-10 05:09:30   IExpressSports   \n",
       "352576 2020-04-09 17:42:01  TalentCanadaMag   \n",
       "\n",
       "                                                     text  \\\n",
       "197806  You know what makes me laugh..this guy who cle...   \n",
       "323869  Thx for that self-aggrandizing rally you held ...   \n",
       "378746  Song about the things we have to think twice a...   \n",
       "55558   #Wimbledon was scheduled to be played on the c...   \n",
       "352576  Employer council urges Quebec to open as many ...   \n",
       "\n",
       "                     source  is_quote  is_retweet  favourites_count  \\\n",
       "197806  Twitter for Android     False       False              2976   \n",
       "323869     Twitter for iPad      True       False             17134   \n",
       "378746      Twitter Web App     False       False             26931   \n",
       "55558             TweetDeck     False       False                33   \n",
       "352576            TweetDeck     False       False               139   \n",
       "\n",
       "        retweet_count  followers_count  friends_count  account_created_at  \\\n",
       "197806              0              204            265 2019-09-30 14:27:58   \n",
       "323869              0             1488           2071 2011-09-27 19:47:27   \n",
       "378746              4            69280          37638 2008-07-12 18:28:11   \n",
       "55558               5            81622            364 2013-08-13 04:44:51   \n",
       "352576              0               53             38 2019-10-21 18:59:02   \n",
       "\n",
       "        verified lang                                       cleaned_text  \n",
       "197806     False   en  know make laugh thi guy clearli would click fi...  \n",
       "323869     False   en  thx self aggrand ralli held walmart target cv ...  \n",
       "378746     False   en  song thing think twice touch due coronaviru covid  \n",
       "55558       True   en  wimbledon wa schedul play club grass court out...  \n",
       "352576     False   en  employ council urg quebec open mani busi possi...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Final Dataset into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.to_csv (r'C:/Users/melin/Documents/Springboard Data Science Career Track/Capstone Projects/Capstone Project 2/df_tweets.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
