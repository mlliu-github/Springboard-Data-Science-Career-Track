{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Working Directory and Concatenate Multiple Datasets into One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory C:\\Users\\melin\n",
      "Directory changed successfully C:\\Users\\melin\\Documents\\Springboard Data Science Career Track\\Capstone Projects\\Capstone Project 2\\COVID-19 Tweets\\CP2data\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\\\Users\\\\melin\\\\Documents\\\\Springboard Data Science Career Track\\\\Capstone Projects\\\\Capstone Project 2\\\\COVID-19 Tweets\\\\CP2data'\n",
    "\n",
    "# Check current working directory.\n",
    "retval = os.getcwd()\n",
    "print(\"Current working directory %s\" % retval)\n",
    "\n",
    "# Now change the directory\n",
    "os.chdir(path)\n",
    "\n",
    "# Check current working directory.\n",
    "retval = os.getcwd()\n",
    "\n",
    "print(\"Directory changed successfully %s\" % retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use glob to match the pattern â€˜csvâ€™\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all files in the list\n",
    "df_tweets = pd.concat([pd.read_csv(f) for f in all_filenames ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>reply_to_status_id</th>\n",
       "      <th>reply_to_user_id</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>country_code</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_type</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>account_lang</th>\n",
       "      <th>account_created_at</th>\n",
       "      <th>verified</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1244051646071611394</td>\n",
       "      <td>860252856829587457</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>IMSS_SanLuis</td>\n",
       "      <td>Ante cualquier enfermedad respiratoria, no te ...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1008</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-05-04T22:00:38Z</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1244051645039706112</td>\n",
       "      <td>1125933654943895553</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>intrac_ccs</td>\n",
       "      <td>#ATENCIÃ“N En el Terminal Nuevo Circo se implem...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-05-08T01:21:16Z</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1244051645975191557</td>\n",
       "      <td>80943559</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>rlieving</td>\n",
       "      <td>â€œPeople are just storing up. They are staying ...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136</td>\n",
       "      <td>457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-10-08T21:06:08Z</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1244051646750928897</td>\n",
       "      <td>817072420947247104</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>Tu_IMSS_Coah</td>\n",
       "      <td>Si empezaste a trabajar, necesitas dar de alta...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1549</td>\n",
       "      <td>170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-05T18:17:00Z</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1244051647032102914</td>\n",
       "      <td>788863557349670913</td>\n",
       "      <td>2020-03-29T00:00:00Z</td>\n",
       "      <td>Tabasco_IMSS</td>\n",
       "      <td>Una sociedad informada estÃ¡ mejor preparada an...</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>868</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-19T22:05:03Z</td>\n",
       "      <td>False</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             status_id              user_id            created_at  \\\n",
       "0  1244051646071611394   860252856829587457  2020-03-29T00:00:00Z   \n",
       "1  1244051645039706112  1125933654943895553  2020-03-29T00:00:00Z   \n",
       "2  1244051645975191557             80943559  2020-03-29T00:00:00Z   \n",
       "3  1244051646750928897   817072420947247104  2020-03-29T00:00:00Z   \n",
       "4  1244051647032102914   788863557349670913  2020-03-29T00:00:00Z   \n",
       "\n",
       "    screen_name                                               text     source  \\\n",
       "0  IMSS_SanLuis  Ante cualquier enfermedad respiratoria, no te ...  TweetDeck   \n",
       "1    intrac_ccs  #ATENCIÃ“N En el Terminal Nuevo Circo se implem...  TweetDeck   \n",
       "2      rlieving  â€œPeople are just storing up. They are staying ...  TweetDeck   \n",
       "3  Tu_IMSS_Coah  Si empezaste a trabajar, necesitas dar de alta...  TweetDeck   \n",
       "4  Tabasco_IMSS  Una sociedad informada estÃ¡ mejor preparada an...  TweetDeck   \n",
       "\n",
       "   reply_to_status_id  reply_to_user_id reply_to_screen_name  is_quote  ...  \\\n",
       "0                 NaN               NaN                  NaN     False  ...   \n",
       "1                 NaN               NaN                  NaN     False  ...   \n",
       "2                 NaN               NaN                  NaN     False  ...   \n",
       "3                 NaN               NaN                  NaN     False  ...   \n",
       "4                 NaN               NaN                  NaN     False  ...   \n",
       "\n",
       "   retweet_count  country_code  place_full_name place_type followers_count  \\\n",
       "0              0           NaN              NaN        NaN            1008   \n",
       "1              1           NaN              NaN        NaN              90   \n",
       "2              0           NaN              NaN        NaN             136   \n",
       "3              0           NaN              NaN        NaN            1549   \n",
       "4              0           NaN              NaN        NaN             868   \n",
       "\n",
       "  friends_count  account_lang    account_created_at  verified lang  \n",
       "0            41           NaN  2017-05-04T22:00:38Z     False   es  \n",
       "1           316           NaN  2019-05-08T01:21:16Z     False   es  \n",
       "2           457           NaN  2009-10-08T21:06:08Z     False   en  \n",
       "3           170           NaN  2017-01-05T18:17:00Z     False   es  \n",
       "4           125           NaN  2016-10-19T22:05:03Z     False   es  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check first 5 rows of df_tweets dataset\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14607013 entries, 0 to 355386\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   status_id             int64  \n",
      " 1   user_id               int64  \n",
      " 2   created_at            object \n",
      " 3   screen_name           object \n",
      " 4   text                  object \n",
      " 5   source                object \n",
      " 6   reply_to_status_id    float64\n",
      " 7   reply_to_user_id      float64\n",
      " 8   reply_to_screen_name  object \n",
      " 9   is_quote              bool   \n",
      " 10  is_retweet            bool   \n",
      " 11  favourites_count      int64  \n",
      " 12  retweet_count         int64  \n",
      " 13  country_code          object \n",
      " 14  place_full_name       object \n",
      " 15  place_type            object \n",
      " 16  followers_count       int64  \n",
      " 17  friends_count         int64  \n",
      " 18  account_lang          float64\n",
      " 19  account_created_at    object \n",
      " 20  verified              bool   \n",
      " 21  lang                  object \n",
      "dtypes: bool(3), float64(3), int64(6), object(10)\n",
      "memory usage: 2.2+ GB\n"
     ]
    }
   ],
   "source": [
    "#Get summary of df_tweets dataframe\n",
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status_id                      0\n",
       "user_id                        0\n",
       "created_at                     0\n",
       "screen_name                    2\n",
       "text                           0\n",
       "source                        83\n",
       "reply_to_status_id      12861933\n",
       "reply_to_user_id        12495830\n",
       "reply_to_screen_name    12495830\n",
       "is_quote                       0\n",
       "is_retweet                     0\n",
       "favourites_count               0\n",
       "retweet_count                  0\n",
       "country_code            13950294\n",
       "place_full_name         13947685\n",
       "place_type              13947685\n",
       "followers_count                0\n",
       "friends_count                  0\n",
       "account_lang            14607013\n",
       "account_created_at             0\n",
       "verified                       0\n",
       "lang                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check sum of missing values in each column of df_tweets dataframe\n",
    "df_tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually Remove Redundant Columns and Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows in which text are not English\n",
    "df_tweets = df_tweets[df_tweets.lang == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove columns with missing percentage of 60% or more\n",
    "df_tweets = df_tweets.loc[:, df_tweets.isnull().mean() < .6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8133785 entries, 2 to 355386\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Dtype \n",
      "---  ------              ----- \n",
      " 0   created_at          object\n",
      " 1   screen_name         object\n",
      " 2   text                object\n",
      " 3   source              object\n",
      " 4   is_quote            bool  \n",
      " 5   is_retweet          bool  \n",
      " 6   favourites_count    int64 \n",
      " 7   retweet_count       int64 \n",
      " 8   followers_count     int64 \n",
      " 9   friends_count       int64 \n",
      " 10  account_created_at  object\n",
      " 11  verified            bool  \n",
      " 12  lang                object\n",
      "dtypes: bool(3), int64(4), object(6)\n",
      "memory usage: 705.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#Remove redundant columns \n",
    "df_tweets = df_tweets.drop(['status_id', 'user_id'], axis = 1)\n",
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(813378, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Randomly drop additional 90% of rows  \n",
    "df_tweets = df_tweets.sample(frac=.1)\n",
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest tweet:  2020-03-29 00:00:00\n",
      "Latest tweet:  2020-04-30 23:59:58 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert created_at and account_created_at variables from object to datetime64 \n",
    "df_tweets['created_at'] = df_tweets['created_at'].astype('datetime64')\n",
    "df_tweets['account_created_at'] = df_tweets['account_created_at'].astype('datetime64')\n",
    "# Check for earliest and latest tweet\n",
    "print(\"Earliest tweet: \", df_tweets['created_at'].min())\n",
    "print(\"Latest tweet: \", df_tweets['created_at'].max(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Twitter Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for converting emoticons to text\n",
    "emoticons = {\n",
    "':-)': 'happy / smile', \n",
    "':)': 'happy / smile', \n",
    "';)': 'wink / glad', \n",
    "':o)': 'happy / smile', \n",
    "':]': 'happy / smile', \n",
    "':3': 'happy / smile', \n",
    "':c)': 'happy / smile',\n",
    "':>': 'happy / smile', \n",
    "'=]': 'happy / smile', \n",
    "'8)': 'happy / smile', \n",
    "'=)': 'happy / smile', \n",
    "':}': 'happy / smile',\n",
    "':^)': 'happy / smile', \n",
    "':-D': 'laugh / big grin',\n",
    "':D': 'laugh / big grin',\n",
    "'8-D': 'laugh / big grin / laugh with glasses / wide-eyed surprise', \n",
    "'8D': 'laugh / big grin / laugh with glasses / wide-eyed surprise', \n",
    "'x-D': 'laugh', \n",
    "'xD': 'laugh', \n",
    "'X-D': 'laugh', \n",
    "'XD': 'laugh', \n",
    "'=-D': 'laugh / big grin', \n",
    "'=D': 'laugh / big grin',\n",
    "'=-3': 'laugh / big grin', \n",
    "'=3': 'laugh / big grin', \n",
    "':-))': 'very happy / double chin', \n",
    "\":'-)\": 'tears of happiness', \n",
    "\":')\": 'tears of happiness', \n",
    "':*': 'kiss', \n",
    "':^*': 'kiss', \n",
    "'>:P': 'tongue sticking out / cheeky / playful / blowing a raspberry', \n",
    "':-P': 'tongue sticking out / cheeky / playful / blowing a raspberry', \n",
    "':P': 'tongue sticking out / cheeky / playful / blowing a raspberry', \n",
    "'X-P': 'tongue sticking out / cheeky / playful / blowing a raspberry',\n",
    "'x-p': 'tongue sticking out / cheeky / playful / blowing a raspberry', \n",
    "'xp': 'tongue sticking out / cheeky / playful / blowing a raspberry', \n",
    "'XP': 'tongue sticking out / cheeky / playful / blowing a raspberry', \n",
    "':-p': 'tongue sticking out / cheeky / playful / blowing a raspberry', \n",
    "':p': 'tongue sticking out / cheeky / playful / blowing a raspberry', \n",
    "'=p': 'tongue sticking out / cheeky / playful / blowing a raspberry', \n",
    "':-b': 'tongue sticking out / cheeky / playful / blowing a raspberry', \n",
    "':b': 'tongue sticking out / cheeky / playful / blowing a raspberry', \n",
    "'>:)': 'devilish / cheeky / playful', \n",
    "'>;)': 'devilish / cheeky / playful / wink', \n",
    "'>:-)': 'devilish / cheeky / playful',\n",
    "'<3': 'heart / love',\n",
    "':L': 'skeptical / undecided / uneasy / hesitant', \n",
    "':-/': 'skeptical / undecided / uneasy / hesitant', \n",
    "'>:/': 'skeptical / annoyed / undecided / uneasy / hesitant', \n",
    "':S': 'skeptical / undecided / uneasy / hesitant', \n",
    "'>:[': 'frown / angry / pouting', \n",
    "':@': 'frown / sad / pouting', \n",
    "':-(': 'frown / sad / pouting', \n",
    "':[': 'frown / sad / pouting', \n",
    "':-||': 'frown / pouting', \n",
    "'=L': 'skeptical / undecided / uneasy / hesitant', \n",
    "':<': 'frown / sad / pouting',\n",
    "':-[': 'frown / sad / pouting', \n",
    "':-<': 'frown / sad / pouting', \n",
    "'=\\\\': 'skeptical / undecided / uneasy / hesitant', \n",
    "'=/': 'skeptical / undecided / uneasy / hesitant', \n",
    "'>:(': 'skeptical / annoyed / undecided / uneasy / hesitant', \n",
    "':(': 'frown / sad / pouting', \n",
    "'>.<': 'frown / pouting', \n",
    "\":'-(\": 'cry', \n",
    "\":'(\": 'cry', \n",
    "':\\\\': 'skeptical / undecided / uneasy / hesitant', \n",
    "':-c': 'frown / sad / pouting',\n",
    "':c': 'frown / sad / pouting', \n",
    "':{': 'frown / sad / pouting', \n",
    "'>:\\\\': 'skeptical / annoyed / undecided / uneasy / hesitant', \n",
    "';(': 'skeptical / annoyed / undecided / uneasy / hesitant'\n",
    "}\n",
    "\n",
    "def emoticon_text(text):\n",
    "    words = text.split()\n",
    "    reformed = [emoticons[word] if word in emoticons else word for word in words]\n",
    "    text = \" \".join(reformed)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply converting emoticons to text function to text column in df_tweets dataframe\n",
    "df_tweets['cleaned_text'] = df_tweets['text'].apply(lambda x: emoticon_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for replacing contractions\n",
    "contractions = { \n",
    "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is / how does\",\n",
    "\"I'd\": \"I had / I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I shall / I will\",\n",
    "\"I'll've\": \"I shall have / I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "def replace_contractions(text):\n",
    "    text = text.replace(\"â€™\",\"'\")\n",
    "    words = text.split()\n",
    "    reformed = [contractions[word] if word in contractions else word for word in words]\n",
    "    text = \" \".join(reformed)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply replace contractions function to cleaned_text column in df_tweets dataframe\n",
    "df_tweets['cleaned_text'] = df_tweets['cleaned_text'].apply(lambda x: replace_contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for twitter text cleaning \n",
    "def tweet_cleaner(text):\n",
    "    text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                  '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', text) #remove url links\n",
    "    text = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", text) #remove twitter handles (@user)\n",
    "    # convert emojis to text\n",
    "    text = emoji.demojize(text)\n",
    "    text = text.replace(\":\",\" \")\n",
    "    # remove punctuations, numbers, and special characters \n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    # remove whitespaces \n",
    "    text = ' '.join(text.split()) \n",
    "    # convert text to lowercase\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply text cleaning function to cleaned_text column in df_tweets dataframe\n",
    "df_tweets['cleaned_text'] = df_tweets['cleaned_text'].apply(lambda x: tweet_cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for lemmatizing words\n",
    "def lemmatize_text(text):\n",
    "    wl = WordNetLemmatizer()\n",
    "    token_words=word_tokenize(str(text))\n",
    "    token_words\n",
    "    lemmatize_text=[]\n",
    "    for word in token_words:\n",
    "        lemmatize_text.append(wl.lemmatize(word))\n",
    "        lemmatize_text.append(\" \")\n",
    "    return \"\".join(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply lemmatizing text function to cleaned_text column in df_tweets dataframe\n",
    "df_tweets['cleaned_text'] = df_tweets['cleaned_text'].apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for stemming words\n",
    "def stem_text(text):\n",
    "    ps = PorterStemmer()\n",
    "    token_words=word_tokenize(str(text))\n",
    "    token_words\n",
    "    stem_text=[]\n",
    "    for word in token_words:\n",
    "        stem_text.append(ps.stem(word))\n",
    "        stem_text.append(\" \")\n",
    "    return \"\".join(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply stemming text function to cleaned_text column in df_tweets dataframe\n",
    "df_tweets['cleaned_text'] = df_tweets['cleaned_text'].apply(lambda x: stem_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop words in cleaned_text column\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    no_stopword_text = [w for w in str(text).split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the remove stop words function to cleaned_text column in df_tweets dataframe\n",
    "df_tweets['cleaned_text'] = df_tweets['cleaned_text'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows containing missing values under the cleaned_text column \n",
    "df_tweets = df_tweets[df_tweets['cleaned_text'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(813378, 14)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>account_created_at</th>\n",
       "      <th>verified</th>\n",
       "      <th>lang</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82964</th>\n",
       "      <td>2020-03-31 04:11:43</td>\n",
       "      <td>sannidhi_perla</td>\n",
       "      <td>1/4\\n@PMOIndia, Amid the #coronavirus lock dow...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>666</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-10-20 15:36:13</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>amid coronaviru lock thi humbl appeal behalf p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546906</th>\n",
       "      <td>2020-04-01 21:49:12</td>\n",
       "      <td>amberbowens</td>\n",
       "      <td>ðŸ¤”Why are they talking about a \"war on drugs\" a...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>224</td>\n",
       "      <td>2009-07-05 22:35:05</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>think face whi talk war drug drug cartel thi r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277509</th>\n",
       "      <td>2020-04-17 14:36:04</td>\n",
       "      <td>bradyparker</td>\n",
       "      <td>Sen. John Thune on paycheck protection program...</td>\n",
       "      <td>IFTTT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4570</td>\n",
       "      <td>2610</td>\n",
       "      <td>2009-05-04 13:41:24</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>sen john thune paycheck protect program run mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14298</th>\n",
       "      <td>2020-04-13 02:13:07</td>\n",
       "      <td>Davidmetroland</td>\n",
       "      <td>@DavidGSmith18 @mindedmusically @Rudy48053087 ...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>31610</td>\n",
       "      <td>0</td>\n",
       "      <td>990</td>\n",
       "      <td>820</td>\n",
       "      <td>2015-05-08 02:30:10</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>air travel make thi type pandem risk coronavir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38635</th>\n",
       "      <td>2020-04-18 03:01:40</td>\n",
       "      <td>yipmann82</td>\n",
       "      <td>@omotforest @matteous_ @anileh2 @GuidoFawkes I...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2865</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>523</td>\n",
       "      <td>2015-08-20 09:50:46</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>see ani front liner say got enough ppe tell fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_at     screen_name  \\\n",
       "82964  2020-03-31 04:11:43  sannidhi_perla   \n",
       "546906 2020-04-01 21:49:12     amberbowens   \n",
       "277509 2020-04-17 14:36:04     bradyparker   \n",
       "14298  2020-04-13 02:13:07  Davidmetroland   \n",
       "38635  2020-04-18 03:01:40       yipmann82   \n",
       "\n",
       "                                                     text  \\\n",
       "82964   1/4\\n@PMOIndia, Amid the #coronavirus lock dow...   \n",
       "546906  ðŸ¤”Why are they talking about a \"war on drugs\" a...   \n",
       "277509  Sen. John Thune on paycheck protection program...   \n",
       "14298   @DavidGSmith18 @mindedmusically @Rudy48053087 ...   \n",
       "38635   @omotforest @matteous_ @anileh2 @GuidoFawkes I...   \n",
       "\n",
       "                     source  is_quote  is_retweet  favourites_count  \\\n",
       "82964       Twitter Web App     False       False               666   \n",
       "546906      Twitter Web App     False       False               608   \n",
       "277509                IFTTT     False       False                 8   \n",
       "14298       Twitter Web App     False       False             31610   \n",
       "38635   Twitter for Android     False       False              2865   \n",
       "\n",
       "        retweet_count  followers_count  friends_count  account_created_at  \\\n",
       "82964               2              116             25 2017-10-20 15:36:13   \n",
       "546906              0              163            224 2009-07-05 22:35:05   \n",
       "277509              0             4570           2610 2009-05-04 13:41:24   \n",
       "14298               0              990            820 2015-05-08 02:30:10   \n",
       "38635               0              326            523 2015-08-20 09:50:46   \n",
       "\n",
       "        verified lang                                       cleaned_text  \n",
       "82964      False   en  amid coronaviru lock thi humbl appeal behalf p...  \n",
       "546906     False   en  think face whi talk war drug drug cartel thi r...  \n",
       "277509     False   en  sen john thune paycheck protect program run mo...  \n",
       "14298      False   en  air travel make thi type pandem risk coronavir...  \n",
       "38635      False   en  see ani front liner say got enough ppe tell fo...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>account_created_at</th>\n",
       "      <th>verified</th>\n",
       "      <th>lang</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80505</th>\n",
       "      <td>2020-04-01 04:34:32</td>\n",
       "      <td>jay1stnewyorker</td>\n",
       "      <td>Coronavirus: White House projects 100,000 to 2...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>519</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>58</td>\n",
       "      <td>2012-05-09 09:41:47</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>coronaviru white hous project death u coronaviru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66469</th>\n",
       "      <td>2020-04-26 07:33:02</td>\n",
       "      <td>KevinJPringle</td>\n",
       "      <td>This weekâ€™s @SundayTimesScot column - a broade...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6630</td>\n",
       "      <td>4</td>\n",
       "      <td>9421</td>\n",
       "      <td>1265</td>\n",
       "      <td>2012-09-26 15:18:17</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>thi week column broader context decentralis ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391416</th>\n",
       "      <td>2020-04-22 22:24:36</td>\n",
       "      <td>leighleigh75</td>\n",
       "      <td>Same ole song and dance #Coronavirus</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>29062</td>\n",
       "      <td>0</td>\n",
       "      <td>421</td>\n",
       "      <td>1797</td>\n",
       "      <td>2009-09-25 12:26:06</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>ole song danc coronaviru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151084</th>\n",
       "      <td>2020-04-08 09:26:42</td>\n",
       "      <td>SKYRIDER4538</td>\n",
       "      <td>@UNNTV1 PETA PETA PETA \\n\\n@peta your silence ...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>167017</td>\n",
       "      <td>8</td>\n",
       "      <td>117138</td>\n",
       "      <td>14269</td>\n",
       "      <td>2015-01-16 08:09:27</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>peta peta peta silenc deafen cri face pensiv f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436533</th>\n",
       "      <td>2020-04-07 23:35:49</td>\n",
       "      <td>CHRYYING</td>\n",
       "      <td>today was a slow day \\n\\n#lofi #LofiHipHop #mu...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>2016-06-19 07:43:56</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>today wa slow day lofi lofihiphop music covid ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_at      screen_name  \\\n",
       "80505  2020-04-01 04:34:32  jay1stnewyorker   \n",
       "66469  2020-04-26 07:33:02    KevinJPringle   \n",
       "391416 2020-04-22 22:24:36     leighleigh75   \n",
       "151084 2020-04-08 09:26:42     SKYRIDER4538   \n",
       "436533 2020-04-07 23:35:49         CHRYYING   \n",
       "\n",
       "                                                     text              source  \\\n",
       "80505   Coronavirus: White House projects 100,000 to 2...  Twitter for iPhone   \n",
       "66469   This weekâ€™s @SundayTimesScot column - a broade...  Twitter for iPhone   \n",
       "391416               Same ole song and dance #Coronavirus  Twitter for iPhone   \n",
       "151084  @UNNTV1 PETA PETA PETA \\n\\n@peta your silence ...  Twitter for iPhone   \n",
       "436533  today was a slow day \\n\\n#lofi #LofiHipHop #mu...  Twitter for iPhone   \n",
       "\n",
       "        is_quote  is_retweet  favourites_count  retweet_count  \\\n",
       "80505      False       False               519              0   \n",
       "66469      False       False              6630              4   \n",
       "391416     False       False             29062              0   \n",
       "151084     False       False            167017              8   \n",
       "436533     False       False                13              0   \n",
       "\n",
       "        followers_count  friends_count  account_created_at  verified lang  \\\n",
       "80505                55             58 2012-05-09 09:41:47     False   en   \n",
       "66469              9421           1265 2012-09-26 15:18:17     False   en   \n",
       "391416              421           1797 2009-09-25 12:26:06     False   en   \n",
       "151084           117138          14269 2015-01-16 08:09:27     False   en   \n",
       "436533                7             21 2016-06-19 07:43:56     False   en   \n",
       "\n",
       "                                             cleaned_text  \n",
       "80505    coronaviru white hous project death u coronaviru  \n",
       "66469   thi week column broader context decentralis ri...  \n",
       "391416                           ole song danc coronaviru  \n",
       "151084  peta peta peta silenc deafen cri face pensiv f...  \n",
       "436533  today wa slow day lofi lofihiphop music covid ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Final Dataset into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.to_csv (r'C:/Users/melin/Documents/Springboard Data Science Career Track/Capstone Projects/Capstone Project 2/df_tweets.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
